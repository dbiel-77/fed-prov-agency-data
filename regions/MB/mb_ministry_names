import requests
from bs4 import BeautifulSoup
import csv

url = "https://www.gov.mb.ca/government/departments.html"
output_file = "mb_ministry_names.csv"

def scrape_ministries(url):
    response = requests.get(url)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, 'html.parser')

    ministries = []

    # Only target the div with class 'col-inside-3'
    content_div = soup.find('div', class_='col-inside-3')
    if not content_div:
        print("No div with class 'col-inside-3' found.")
        return ministries

    # Loop through all <ul> elements inside the target div
    for ul in content_div.find_all('ul'):
        for li in ul.find_all('li', recursive=False):
            a_tag = li.find('a', href=True)
            if a_tag:
                name = a_tag.get_text(strip=True)
                href = a_tag['href']
                full_url = "https:" + href if href.startswith("//") else href
                ministries.append((name, full_url))

            # Handle nested <ul> lists (e.g., Francophone Affairs Secretariat)
            nested_ul = li.find('ul')
            if nested_ul:
                for sub_li in nested_ul.find_all('li'):
                    sub_a = sub_li.find('a', href=True)
                    if sub_a:
                        sub_name = sub_a.get_text(strip=True)
                        sub_href = sub_a['href']
                        sub_url = "https:" + sub_href if sub_href.startswith("//") else sub_href
                        ministries.append((sub_name, sub_url))

    return ministries

def save_to_csv(data, filename):
    with open(filename, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Ministry Name', 'Ministry URL'])
        writer.writerows(data)

if __name__ == "__main__":
    ministries = scrape_ministries(url)
    save_to_csv(ministries, output_file)
    print(f"Saved {len(ministries)} ministries to {output_file}")
